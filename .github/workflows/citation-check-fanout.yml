name: citation-check-fanout

on:
  workflow_dispatch:

jobs:
  run-gpt-oss-fanout:
    runs-on: ubuntu-latest
    env:
      OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
      MODEL_SLUGS: openai/gpt-oss-20b:free:online
      PROMPTS_PATH: config/prompts_fanout.txt
      TARGETS_PATH: config/targets_fanout.json
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: python -m pip install --upgrade pip requests python-dotenv

      - name: Run gpt-oss-20b free online (fanout)
        run: python run.py

      - name: Job summary
        run: cat logs/last_summary.md >> $GITHUB_STEP_SUMMARY

      - name: Upload logs
        uses: actions/upload-artifact@v4
        with:
          name: logs-gpt-oss-fanout
          path: logs/

  run-claude-haiku-fanout:
    runs-on: ubuntu-latest
    needs: run-gpt-oss-fanout
    env:
      OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
      MODEL_SLUGS: anthropic/claude-3.5-haiku:online
      PROMPTS_PATH: config/prompts_fanout.txt
      TARGETS_PATH: config/targets_fanout.json
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: python -m pip install --upgrade pip requests python-dotenv

      - name: Run claude 3.5 haiku online (fanout)
        run: python run.py

      - name: Job summary
        run: cat logs/last_summary.md >> $GITHUB_STEP_SUMMARY

      - name: Upload logs
        uses: actions/upload-artifact@v4
        with:
          name: logs-claude-haiku-fanout
          path: logs/

  run-perplexity-sonar-fanout:
    runs-on: ubuntu-latest
    needs: run-claude-haiku-fanout
    env:
      OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
      MODEL_SLUGS: perplexity/sonar:online
      PROMPTS_PATH: config/prompts_fanout.txt
      TARGETS_PATH: config/targets_fanout.json
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: python -m pip install --upgrade pip requests python-dotenv

      - name: Run perplexity sonar online (fanout)
        run: python run.py

      - name: Job summary
        run: cat logs/last_summary.md >> $GITHUB_STEP_SUMMARY

      - name: Upload logs
        uses: actions/upload-artifact@v4
        with:
          name: logs-perplexity-sonar-fanout
          path: logs/

  commit-logs-fanout:
    runs-on: ubuntu-latest
    needs: run-perplexity-sonar-fanout
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Merge logs
        run: |
          set -e
          mkdir -p logs
          python - <<'PY'
          import pathlib
          import shutil

          root = pathlib.Path("artifacts")
          log_dir = pathlib.Path("logs")
          log_dir.mkdir(exist_ok=True)

          artifact_logs = sorted(root.glob("*/logs"))

          # Merge run_*.json files and master_log.jsonl
          master_out = (log_dir / "master_log.jsonl").open("w", encoding="utf-8")
          main_log_path = log_dir / "main_log.md"
          main_written = {"done": False}

          def append_main(src: pathlib.Path):
            text = src.read_text(encoding="utf-8")
            if not main_written["done"]:
              main_log_path.write_text(text, encoding="utf-8")
              main_written["done"] = True
              return
            # Append without duplicating the header line
            lines = text.splitlines()
            trimmed = lines
            if trimmed and trimmed[0].startswith("# Citation runs"):
              trimmed = trimmed[1:]
            with main_log_path.open("a", encoding="utf-8") as handle:
              handle.write("\n".join(trimmed) + "\n")

          for src_logs in artifact_logs:
            # Copy run-level JSON files
            for run_file in src_logs.glob("run_*.json"):
              shutil.copy(run_file, log_dir / run_file.name)

            # Append master_log.jsonl content
            master_file = src_logs / "master_log.jsonl"
            if master_file.exists():
              for line in master_file.read_text(encoding="utf-8").splitlines():
                master_out.write(line + "\n")

            # Merge main_log.md
            main_file = src_logs / "main_log.md"
            if main_file.exists():
              append_main(main_file)

          master_out.close()
          PY

      - name: Commit and push logs
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add -f logs/*.json logs/*.jsonl logs/main_log.md || true
          if git diff --cached --quiet; then
            echo "No log changes to commit."
          else
            git commit -m "Update citation logs (fanout) [skip ci]" || true
            git push origin HEAD:${GITHUB_REF#refs/heads/} || true
          fi

      - name: Notify Slack
        if: always()
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        run: |
          set -eo pipefail
          summary_file="logs/last_summary.md"
          if [ -f "$summary_file" ]; then
            summary_text=$(cat "$summary_file")
          else
            summary_text=$(cat logs/main_log.md)
          fi
          export SUMMARY="$summary_text"
          payload=$(python -c $'import json, os\n\n'"'"'def format_table(md):\n    lines = md.splitlines()\n    table = []\n    prefix = []\n    in_table = False\n    for ln in lines:\n        st = ln.strip()\n        if st.startswith("|") and st.endswith("|") and "|" in st[1:-1]:\n            parts = [p.strip() for p in st.strip("|").split("|")]\n            if all(set(p) <= set("-:")):\n                in_table = True\n                continue\n            in_table = True\n            table.append(parts)\n        else:\n            if not in_table:\n                prefix.append(ln)\n    if not table:\n        return md\n    widths = [max(len(r[i]) for r in table) for i in range(len(table[0]))]\n    table_lines = [" | ".join(r[i].ljust(widths[i]) for i in range(len(widths))) for r in table]\n    body = "\\n".join([ln for ln in prefix if ln.strip()])\n    if body:\n        body += "\\n"\n    body += "\\n".join(table_lines)\n    return body\n\n'"'"'\nw=os.getenv("GITHUB_WORKFLOW","citation-check-fanout")\ns=os.getenv("SUMMARY","").strip().replace("<br>","\\n").replace("\\r\\n","\\n")\nsummary_text=s if s else "No summary available."\nformatted=format_table(summary_text)\ntitle=f"Citation check finished for {w}"\nsummary_block=f"```\\n{formatted}\\n```"\npayload={"channel":"C0A7QE8K7R8","text":title,"blocks":[{"type":"section","text":{"type":"mrkdwn","text":f"*{title}*"}},{"type":"section","text":{"type":"mrkdwn","text":"Summary below."}},{"type":"section","text":{"type":"mrkdwn","text":summary_block}}]}\nprint(json.dumps(payload))')
          curl -X POST https://slack.com/api/chat.postMessage \
            -H "Authorization: Bearer $SLACK_BOT_TOKEN" \
            -H "Content-Type: application/json" \
            --data "$payload"
